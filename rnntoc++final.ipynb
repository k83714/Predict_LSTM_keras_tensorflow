{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (240, 3120) (3120, 1)\n",
      "total time: 240 \n",
      "(231, 10, 3120)\n",
      "(231, 1)\n",
      "data process done...\n",
      "(154, 10, 3120)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, LSTM, Recurrent, Dropout, Conv1D, Embedding\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, Embedding\n",
    "\n",
    "#### Hyper Parameters\n",
    "np.random.seed(0)  # Random Seed\n",
    "N_time_steps = 10  # Time steps of the RNN network\n",
    "units_list = [20, 50]  # In each layer, for every unit use how many hidden neurons\n",
    "batch_size = 4  # Each time use how many samples\n",
    "epochs = 20  # How many epochs to train the model\n",
    "path = 'irs-tap-traces/'  # Folder that source data is saved\n",
    "X=  loadmat(path+'irs-1.mat')['abs_irs']\n",
    "y= loadmat(path+'tap-1.mat')['gt_tap']\n",
    "\n",
    "\n",
    "#### Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X.T)  # Use X.Transpose to normalize among each signals\n",
    "X = X.T\n",
    "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
    "y = scaler1.fit_transform(y)\n",
    "print(type(X), X.shape, y.shape)\n",
    "\n",
    "#### Reshape 2-D X (samples, signals) into 3-D (samples * time-steps * window-size)\n",
    "total_time = X.shape[0]\n",
    "print('total time: %d ' % total_time)\n",
    "start_idx = 1\n",
    "end_idx = X.shape[0] - N_time_steps + 1\n",
    "X_3d = np.zeros((end_idx, N_time_steps, X.shape[1]))   #initial\n",
    "y_3d = np.zeros((end_idx, 1))\n",
    "for i in range(end_idx):\n",
    "    X_3d[i, :, :] = X[i:i+N_time_steps, :]\n",
    "    y_3d[i] = y[i + 9]\n",
    "print(X_3d.shape)\n",
    "print(y_3d.shape)\n",
    "print('data process done...')\n",
    "\n",
    "\n",
    "train_size = int(len(X_3d) * 0.67)\n",
    "test_size = len(X_3d) - train_size\n",
    "X_train, X_test = X_3d[:train_size, :], X_3d[train_size:len(X), :]\n",
    "y_train, y_test = y_3d[:train_size, :], y_3d[train_size:len(X), :]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 10, 20)            251280    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 20)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50)                14200     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 265,531\n",
      "Trainable params: 265,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "{'name': 'sequential_5', 'layers': [{'class_name': 'LSTM', 'config': {'name': 'lstm_8', 'trainable': True, 'batch_input_shape': (None, 10, 3120), 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 20, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'LSTM', 'config': {'name': 'lstm_9', 'trainable': True, 'batch_input_shape': (None, 10, 3120), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 50, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}], 'build_input_shape': TensorShape([None, 10, 3120])}\n",
      "Epoch 1/20\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.8341e-04\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.1101e-04\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.6007e-05\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 3.4235e-05\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.0499e-05\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 5.5686e-05\n",
      "Epoch 7/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.1980e-05\n",
      "Epoch 8/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.0494e-05\n",
      "Epoch 9/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.1383e-05\n",
      "Epoch 10/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.5476e-05\n",
      "Epoch 11/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.4650e-05\n",
      "Epoch 12/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.2869e-05\n",
      "Epoch 13/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.4669e-05\n",
      "Epoch 14/20\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.3033e-05\n",
      "Epoch 15/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.6352e-05\n",
      "Epoch 16/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.0830e-05\n",
      "Epoch 17/20\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.0850e-05\n",
      "Epoch 18/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.4273e-05\n",
      "Epoch 19/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.4399e-05\n",
      "Epoch 20/20\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 8.5843e-06\n"
     ]
    }
   ],
   "source": [
    "#N_time_steps=5\n",
    "#ll=11\n",
    "#outll=1\n",
    "#X_train, X_test = X_3d[:2, 0:N_time_steps, 0:ll], X_3d[2:3, 0:N_time_steps, 0:ll]\n",
    "#y_train, y_test = y_3d[:2, 0:1], y_3d[2:3, 0:1]\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "\n",
    "units_lists=[20,50]\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(128, kernel_size=1, activation='relu', input_shape=(N_time_steps, X.shape[1])))\n",
    "model.add(LSTM(input_shape=(N_time_steps, X.shape[1]), units=units_list[0], return_sequences=True))  # First Layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(input_shape=(N_time_steps, X.shape[1]), units=units_list[1], return_sequences=False))  # Second Layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "print(model.get_config())\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1);\n",
    "#model.fit(X_train, y_train, epochs=epochs, verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].shape)\n",
    "npweights = np.array(weights)\n",
    "\n",
    "for i in range(len(weights)):    \n",
    "    if( len(npweights[i].shape) == 2):\n",
    "        weights[i] = weights[i][0:2, 0:4]\n",
    "    if( len(npweights[i].shape) == 1):\n",
    "        weights[i] = weights[i][0:2]\n",
    "\n",
    "print(weights)\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].shape)\n",
    "for i in range(len(weights)):\n",
    "    if( len(weights[i].shape) == 2):\n",
    "        weights[i] = weights[i][0:2, 0:4]\n",
    "    if( len(weights[i].shape) == 1):\n",
    "        weights[i] = weights[i][0:2]\n",
    "\n",
    "        \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265531,)\n",
      "[ 0.026374  0.137397 -0.123673 -0.039094] [ 0.079275  0.101554  0.04169  -0.159007]\n",
      "[-0.096018 -0.01741   0.150495  0.090195] 0.28609195351600647 0.012956217862665653\n",
      "---\n",
      "[0.00557  0.005034] [0.00606  0.005377] [0.00606  0.005377]\n",
      "[[[0.00557  0.005034 0.004171 ... 0.001261 0.002294 0.002928]\n",
      "  [0.00606  0.005377 0.004575 ... 0.001345 0.002522 0.003226]\n",
      "  [0.006536 0.005758 0.005044 ... 0.001315 0.002644 0.003383]]\n",
      "\n",
      " [[0.00606  0.005377 0.004575 ... 0.001345 0.002522 0.003226]\n",
      "  [0.006536 0.005758 0.005044 ... 0.001315 0.002644 0.003383]\n",
      "  [0.007027 0.006216 0.005586 ... 0.001199 0.002703 0.003411]]]\n",
      "--test.shape:\n",
      "(2, 10, 3120)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "weights = np.array(model.get_weights())\n",
    "#for i in range(2):\n",
    "    #    print(weights[0][i][0:3])\n",
    "    #    print(weights[1][i][0:3])\n",
    "    #    print(weights[2][i])\n",
    "#for i in range(len(weights)):\n",
    "   # print(weights[i].shape)\n",
    "#print(weights[0][0][0:3])\n",
    "\n",
    "flatweights=np.array([])\n",
    "for i in range(8):    \n",
    "    weights[i] = weights[i].flatten();\n",
    "    flatweights = np.hstack((flatweights, weights[i]))\n",
    "\n",
    "\n",
    "\n",
    "print(flatweights.shape)\n",
    "print(flatweights[251280:251280+4], flatweights[251280 + 200:251280+200+4])\n",
    "print(flatweights[265480:265480+4], flatweights[265480 + 49], flatweights[265480 + 50])\n",
    "#for i in range(len(weights)):\n",
    "#    np.savetxt('weights%d.txt' % i, weights[i], newline='\\n')\n",
    "np.savetxt('flatweights.txt', flatweights, fmt=\"%e\")\n",
    "xtestp=X_test[0:2]\n",
    "xtestflat = xtestp.flatten()\n",
    "np.savetxt('flattest.txt', xtestflat, fmt=\"%e\")\n",
    "print ('---')\n",
    "print(xtestflat[0:2],xtestflat[3120:3122], xtestflat[10*3120:31200+2])\n",
    "print(xtestp[0:2, 0:3])\n",
    "print(\"--test.shape:\")\n",
    "print(X_test.shape)\n",
    "prey=model.predict(X_test)\n",
    "print(np.array(prey).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1.0/(1.0+np.exp(-x)))\n",
    "\n",
    "def LSTMlayer(warr,uarr, barr,x_t,h_tm1,c_tm1):\n",
    "\n",
    "\n",
    "    s_t = (x_t.dot(warr) + h_tm1.dot(uarr) + barr)\n",
    "    #print(x_t[0, 0:5], warr[0, 0:5], h_tm1[0, 0:5], uarr[0, 0:5], barr[0:5])\n",
    "    #print(s_t[0, 0:10])\n",
    "    hunit = uarr.shape[0]\n",
    "    i  = sigmoid(s_t[:,:hunit])\n",
    "    f  = sigmoid(s_t[:,1*hunit:2*hunit])\n",
    "    _c = np.tanh(s_t[:,2*hunit:3*hunit])\n",
    "    o  = sigmoid(s_t[:,3*hunit:])\n",
    "    #print(i[0,0:5], f[0,0:5], _c[0,0:5], o[0,0:5]);\n",
    "    c_t = i*_c + f*c_tm1\n",
    "    h_t = o*np.tanh(c_t)\n",
    "    #print(h_t[0, 0:5])\n",
    "    #print(\"\")\n",
    "    #print(\"\")\n",
    "    return(h_t,c_t)\n",
    "\n",
    "\n",
    "def DenseLayer(x, w, b):\n",
    "    return x.dot(w)+b;\n",
    "\n",
    "# n: window size\n",
    "# hunits: output dim\n",
    "# inputlen: input dim\n",
    "def intermediate_out(n,warr,uarr,barr, X_test, hunits, inputlen):\n",
    "    for i in range(0, n+1):\n",
    "        if i==0:\n",
    "            c_tm1 = np.array([0]*hunits, dtype=np.float32).reshape(1,hunits)\n",
    "            h_tm1 = np.array([0]*hunits, dtype=np.float32).reshape(1,hunits)\n",
    "            h_t,ct = LSTMlayer(warr,uarr, barr,X_test[0:1, 0:inputlen],h_tm1,c_tm1)\n",
    "        else:\n",
    "            h_t,ct = LSTMlayer(warr,uarr, barr,X_test[i:i+1, 0:inputlen],h_t,ct)\n",
    "    return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputlen1\n",
      "3120\n",
      "(2, 10, 3120)\n",
      "(77, 1)\n",
      "(2, 10, 20)\n",
      "[[0.038122]\n",
      " [0.035279]]\n",
      "[[ 5.188636e-03 -5.976483e-04 -2.311663e-03  8.572704e-03  5.661738e-03\n",
      "  -9.532309e-03  2.895232e-03  4.375157e-03  2.059858e-03 -1.228063e-04\n",
      "  -5.630913e-03 -2.585759e-03  3.775928e-03  4.204208e-03  4.335599e-03\n",
      "   3.888438e-03  1.922139e-03 -5.025594e-03 -5.130682e-03 -4.510193e-03]\n",
      " [ 8.289863e-03 -1.463899e-03 -2.871907e-03  1.466659e-02  1.034203e-02\n",
      "  -1.538972e-02  4.517830e-03  7.927158e-03  2.809095e-03  7.943323e-05\n",
      "  -9.658235e-03 -4.104369e-03  5.577469e-03  7.018458e-03  6.357080e-03\n",
      "   5.708643e-03  4.082741e-03 -9.161425e-03 -8.458011e-03 -7.608317e-03]]\n"
     ]
    }
   ],
   "source": [
    "tmp = X_test\n",
    "X_test=X_test[0:2]\n",
    "hunits=20\n",
    "windowsize=10\n",
    "\n",
    "weightLSTM = np.array(model.get_weights()[0:3])\n",
    "warr,uarr, barr = weightLSTM\n",
    "\n",
    "inputlen = X_test.shape[2]\n",
    "samplenum = X_test.shape[0]\n",
    "print(\"inputlen1\")\n",
    "print(inputlen)\n",
    "xlstm1 = np.zeros((X_test.shape[0], 10, hunits))\n",
    "print(X_test.shape)\n",
    "\n",
    "for n in range(samplenum):\n",
    "    for i in range(windowsize):\n",
    "        xlstm1[n][i] = intermediate_out(i,warr,uarr,barr,X_test[n], hunits, inputlen)\n",
    "\n",
    "output1len = hunits\n",
    "\n",
    "    \n",
    "## layer lstm 2\n",
    "\n",
    "print(prey.shape)\n",
    "print(xlstm1.shape)\n",
    "print(prey[0:2])\n",
    "print(xlstm1[1, 0:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.010914 -0.091002 -0.075239  0.127657]\n",
      " [-0.031738 -0.087789  0.127712  0.125736]]\n",
      "inputlen2, samplenum\n",
      "20 2 (2, 50)\n",
      "[ 8.534716e-05  2.616592e-03 -4.559041e-03 -4.810492e-03 -9.369729e-03] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0. 0. 0. 0. 0.] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.029137 -0.001793  0.000263 -0.027276 -0.014286 -0.01623  -0.014642\n",
      " -0.026064 -0.029986 -0.01028 ]\n",
      "[0.492716 0.499552 0.500066 0.493181 0.496428] [0.72641  0.731268 0.73071  0.72606  0.730487] [0.014616 0.018992 0.02938  0.011996 0.018104] [0.492199 0.50006  0.500234 0.493874 0.496534]\n",
      "[0.003544 0.004744 0.007349 0.002922 0.004462]\n",
      "\n",
      "\n",
      "[-7.627251e-05  3.731392e-03 -7.745006e-03 -8.995222e-03 -1.641552e-02] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.003544 0.004744 0.007349 0.002922 0.004462] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.02751  -0.003116  0.002601 -0.030118 -0.015355 -0.01326  -0.015074\n",
      " -0.025879 -0.02794  -0.008948]\n",
      "[0.493123 0.499221 0.50065  0.492471 0.496161] [0.726341 0.731458 0.730533 0.726852 0.731409] [0.019543 0.024916 0.031992 0.016748 0.02344 ] [0.492523 0.499743 0.500706 0.493683 0.496475]\n",
      "[0.007322 0.009683 0.01339  0.006194 0.009037]\n",
      "\n",
      "\n",
      "[-0.000487  0.00396  -0.009951 -0.012377 -0.021527] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.007322 0.009683 0.01339  0.006194 0.009037] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.025477 -0.004666  0.004859 -0.032525 -0.015783 -0.010351 -0.015528\n",
      " -0.024762 -0.026894 -0.007647]\n",
      "[0.493631 0.498833 0.501215 0.49187  0.496054] [0.726193 0.731633 0.730513 0.72771  0.732159] [0.023947 0.029178 0.033443 0.021381 0.027585] [0.492906 0.499229 0.501024 0.493507 0.496589]\n",
      "[0.011146 0.01434  0.018181 0.009695 0.01341 ]\n",
      "\n",
      "\n",
      "[-0.001011  0.003632 -0.011494 -0.015007 -0.025133] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.011146 0.01434  0.018181 0.009695 0.01341 ] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.023188 -0.006316  0.006946 -0.034422 -0.015693 -0.007663 -0.015965\n",
      " -0.022967 -0.026611 -0.006335]\n",
      "[0.494203 0.498421 0.501736 0.491395 0.496077] [0.726011 0.731785 0.730599 0.728565 0.732751] [0.027742 0.032105 0.034125 0.02563  0.030708] [0.493286 0.498624 0.501175 0.493323 0.496851]\n",
      "[0.014859 0.018454 0.02186  0.013272 0.017396]\n",
      "\n",
      "\n",
      "[-0.001181  0.003267 -0.012625 -0.017218 -0.027825] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.014859 0.018454 0.02186  0.013272 0.017396] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.020836 -0.008009  0.008854 -0.035833 -0.015254 -0.005191 -0.016392\n",
      " -0.020734 -0.026901 -0.005009]\n",
      "[0.494791 0.497998 0.502213 0.491043 0.496187] [0.72582  0.731905 0.730742 0.72938  0.733228] [0.030983 0.034103 0.034499 0.029387 0.033093] [0.493589 0.498009 0.501201 0.493138 0.497225]\n",
      "[0.018353 0.02194  0.024649 0.016789 0.020922]\n",
      "\n",
      "\n",
      "[-0.001029  0.00272  -0.013488 -0.019109 -0.029791] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.018353 0.02194  0.024649 0.016789 0.020922] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.018583 -0.009625  0.010554 -0.036827 -0.014591 -0.002995 -0.016787\n",
      " -0.018334 -0.027642 -0.003643]\n",
      "[0.495354 0.497594 0.502638 0.490794 0.496352] [0.725621 0.731999 0.730913 0.73013  0.733598] [0.033719 0.035444 0.034603 0.032653 0.034816] [0.493816 0.497436 0.501115 0.492936 0.497675]\n",
      "[0.021564 0.024804 0.026718 0.020146 0.023953]\n",
      "\n",
      "\n",
      "[-0.000207  0.002248 -0.014222 -0.02091  -0.031315] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.021564 0.024804 0.026718 0.020146 0.023953] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.016594 -0.011132  0.012055 -0.037468 -0.013882 -0.00105  -0.017203\n",
      " -0.015954 -0.028716 -0.002241]\n",
      "[0.495852 0.497217 0.503014 0.490634 0.496529] [0.725417 0.732069 0.731091 0.730799 0.733891] [0.03603  0.036439 0.0346   0.035413 0.036057] [0.49394  0.496948 0.500957 0.492728 0.498167]\n",
      "[0.024461 0.027133 0.028235 0.023268 0.026504]\n",
      "\n",
      "\n",
      "[ 0.001101  0.001488 -0.014706 -0.022277 -0.031871] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.024461 0.027133 0.028235 0.023268 0.026504] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.014995 -0.012377  0.01322  -0.037722 -0.01325   0.000491 -0.017671\n",
      " -0.013784 -0.030071 -0.000833]\n",
      "[0.496251 0.496906 0.503305 0.49057  0.496688] [0.725198 0.732142 0.731303 0.731365 0.734079] [0.037818 0.03705  0.034052 0.037552 0.036642] [0.494023 0.49657  0.500703 0.492495 0.498651]\n",
      "[0.027001 0.028978 0.029208 0.02607  0.028537]\n",
      "\n",
      "\n",
      "[ 0.002194 -0.000439 -0.014444 -0.022236 -0.030158] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.027001 0.028978 0.029208 0.02607  0.028537] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.013717 -0.013151  0.013808 -0.037479 -0.012659  0.00134  -0.018227\n",
      " -0.011962 -0.031819  0.000308]\n",
      "[0.496571 0.496712 0.503452 0.490631 0.496835] [0.724941 0.732263 0.731614 0.731794 0.734069] [0.038766 0.03675  0.032051 0.038859 0.036047] [0.494198 0.496253 0.500313 0.492215 0.499091]\n",
      "[0.029081 0.030252 0.029415 0.028438 0.029892]\n",
      "\n",
      "\n",
      "[ 0.001548 -0.003803 -0.012457 -0.019578 -0.025212] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.029081 0.030252 0.029415 0.028438 0.029892] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.012836 -0.013194  0.013705 -0.036754 -0.012171  0.001019 -0.01893\n",
      " -0.010462 -0.033969  0.000874]\n",
      "[0.496791 0.496702 0.503426 0.490812 0.496957] [0.724646 0.732435 0.732052 0.73207  0.733755] [0.038572 0.03484  0.027954 0.039097 0.033875] [0.494589 0.495927 0.499735 0.491891 0.499468]\n",
      "[0.030553 0.030713 0.028535 0.030229 0.030347]\n",
      "\n",
      "\n",
      "[-0.000347  0.002449 -0.00456  -0.004585 -0.009305] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0. 0. 0. 0. 0.] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.028993 -0.001744  0.00021  -0.027338 -0.014214 -0.016293 -0.014631\n",
      " -0.026084 -0.029861 -0.010324]\n",
      "[0.492752 0.499564 0.500052 0.493166 0.496447] [0.726417 0.731277 0.730715 0.726044 0.730489] [0.014603 0.01898  0.029325 0.011911 0.01813 ] [0.49226  0.500047 0.500227 0.493883 0.49652 ]\n",
      "[0.003542 0.004741 0.007335 0.002901 0.004469]\n",
      "\n",
      "\n",
      "[-0.000761  0.003418 -0.007795 -0.008526 -0.016195] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.003542 0.004741 0.007335 0.002901 0.004469] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.027211 -0.003078  0.002481 -0.030149 -0.015161 -0.013369 -0.015065\n",
      " -0.025854 -0.027785 -0.009017]\n",
      "[0.493198 0.499231 0.50062  0.492463 0.49621 ] [0.726344 0.731477 0.730557 0.726831 0.7314  ] [0.019468 0.024822 0.031822 0.016599 0.023409] [0.492621 0.499714 0.500677 0.493684 0.496461]\n",
      "[0.007304 0.009657 0.013337 0.006143 0.009034]\n",
      "\n",
      "\n",
      "[-0.001206  0.003493 -0.01008  -0.011756 -0.021169] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.007304 0.009657 0.013337 0.006143 0.009034] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.025079 -0.004664  0.004666 -0.03247  -0.015455 -0.010491 -0.015507\n",
      " -0.024678 -0.026785 -0.007695]\n",
      "[0.493731 0.498834 0.501166 0.491883 0.496136] [0.726186 0.731659 0.730559 0.727686 0.732131] [0.023786 0.028978 0.033144 0.021186 0.02744 ] [0.493011 0.499188 0.500964 0.49349  0.496587]\n",
      "[0.011097 0.014271 0.018065 0.00961  0.013374]\n",
      "\n",
      "\n",
      "[-0.001273  0.003339 -0.011731 -0.01454  -0.024894] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.011097 0.014271 0.018065 0.00961  0.013374] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.0228   -0.006386  0.006713 -0.034282 -0.015299 -0.007747 -0.015943\n",
      " -0.022839 -0.026579 -0.00634 ]\n",
      "[0.4943   0.498403 0.501678 0.49143  0.496175] [0.725992 0.731807 0.730655 0.728541 0.732725] [0.02754  0.031917 0.033889 0.025408 0.030544] [0.493337 0.498592 0.501107 0.493299 0.496865]\n",
      "[0.014774 0.018357 0.021715 0.013156 0.01733 ]\n",
      "\n",
      "\n",
      "[-0.001024  0.002894 -0.012949 -0.01695  -0.027643] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.014774 0.018357 0.021715 0.013156 0.01733 ] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.02055  -0.00809   0.008574 -0.035633 -0.014838 -0.005251 -0.016343\n",
      " -0.020652 -0.026982 -0.004919]\n",
      "[0.494863 0.497978 0.502143 0.491093 0.496291] [0.725776 0.731926 0.730806 0.729351 0.733192] [0.03075  0.033969 0.0342   0.02918  0.032834] [0.493591 0.498    0.501114 0.493093 0.497255]\n",
      "[0.018234 0.021836 0.024466 0.016653 0.020812]\n",
      "\n",
      "\n",
      "[-0.000128  0.002461 -0.013918 -0.019203 -0.029757] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.018234 0.021836 0.024466 0.016653 0.020812] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.01851  -0.009717  0.010242 -0.036578 -0.014267 -0.003008 -0.016759\n",
      " -0.018347 -0.027835 -0.00344 ]\n",
      "[0.495373 0.497571 0.50256  0.490857 0.496433] [0.72555  0.732016 0.730979 0.73009  0.733564] [0.033485 0.035492 0.034304 0.032441 0.03452 ] [0.49374  0.497474 0.501022 0.492879 0.497718]\n",
      "[0.021416 0.024743 0.026508 0.019995 0.023802]\n",
      "\n",
      "\n",
      "[ 0.001229  0.001706 -0.014551 -0.020955 -0.030762] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.021416 0.024743 0.026508 0.019995 0.023802] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-0.016817 -0.011099  0.011575 -0.037085 -0.013719 -0.001186 -0.017225\n",
      " -0.016149 -0.029056 -0.001938]\n",
      "[0.495796 0.497225 0.502894 0.49073  0.49657 ] [0.725307 0.732106 0.731196 0.730728 0.733816] [0.035646 0.036488 0.033807 0.035049 0.035455] [0.493847 0.497049 0.500812 0.492638 0.498196]\n",
      "[0.024255 0.027105 0.027878 0.023068 0.026243]\n",
      "\n",
      "\n",
      "[ 0.002349 -0.000236 -0.014377 -0.021225 -0.029371] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.024255 0.027105 0.027878 0.023068 0.026243] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-1.541967e-02 -1.201494e-02  1.232201e-02 -3.703893e-02 -1.317177e-02\n",
      " -8.780702e-05 -1.777925e-02 -1.422604e-02 -3.073575e-02 -6.903534e-04]\n",
      "[0.496145 0.496996 0.50308  0.490741 0.496707] [0.72503  0.732239 0.731518 0.731229 0.733857] [0.036917 0.036459 0.03182  0.036775 0.035129] [0.494042 0.496681 0.500447 0.492349 0.498648]\n",
      "[0.02663  0.02882  0.02838  0.025733 0.027965]\n",
      "\n",
      "\n",
      "[ 0.001714 -0.003622 -0.01244  -0.018814 -0.024652] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.02663  0.02882  0.02838  0.025733 0.027965] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-1.440410e-02 -1.219692e-02  1.236788e-02 -3.646433e-02 -1.269545e-02\n",
      " -1.914579e-04 -1.848433e-02 -1.257779e-02 -3.286867e-02 -1.247232e-05]\n",
      "[0.496399 0.496951 0.503092 0.490885 0.496826] [0.724717 0.732421 0.731969 0.731572 0.733582] [0.036999 0.034732 0.02772  0.037376 0.033162] [0.49445  0.496305 0.49988  0.492014 0.499049]\n",
      "[0.028384 0.029647 0.027715 0.027827 0.028743]\n",
      "\n",
      "\n",
      "[-0.001654 -0.00766  -0.008389 -0.013456 -0.016716] [-0.010914 -0.091002 -0.075239  0.127657  0.008229] [0.028384 0.029647 0.027715 0.027827 0.028743] [0.040828 0.075186 0.138159 0.076118 0.085629] [-0.029422 -0.001511 -0.001138 -0.024965 -0.013731]\n",
      "[-1.394034e-02 -1.149934e-02  1.171728e-02 -3.537780e-02 -1.241635e-02\n",
      " -1.818615e-03 -1.937176e-02 -1.124200e-02 -3.517362e-02  1.145536e-05]\n",
      "[0.496515 0.497125 0.502929 0.491156 0.496896] [0.724397 0.732603 0.732515 0.731744 0.732976] [0.03575  0.031166 0.021781 0.036674 0.029637] [0.495081 0.495952 0.499099 0.491669 0.499374]\n",
      "[0.029363 0.029379 0.025735 0.029192 0.028428]\n",
      "\n",
      "\n",
      "[0.030553 0.030713 0.028535 0.030229 0.030347 0.030754 0.030433 0.030314\n",
      " 0.030336 0.029989]\n",
      "[0.030553 0.030713 0.028535 0.030229 0.030347 0.030754 0.030432 0.030314\n",
      " 0.030336 0.029989]\n",
      "[0.029363 0.029379 0.025735 0.029192 0.028428 0.029076 0.028408 0.02916\n",
      " 0.028744 0.028219]\n",
      "[0.029363 0.029379 0.025735 0.029192 0.028428 0.029076 0.028408 0.02916\n",
      " 0.028744 0.028219]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-4faeb666c6a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mweightDENSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mwarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweightDENSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mxdense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxlstm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "hunits = 50\n",
    "windowsize = 10\n",
    "\n",
    "weightLSTM2 = np.array(model.get_weights()[3:6])\n",
    "warr,uarr, barr = weightLSTM2\n",
    "\n",
    "print(weightLSTM2[0][0:2, 0:4])\n",
    "inputlen = xlstm1.shape[2]\n",
    "samplenum = xlstm1.shape[0]\n",
    "xlstm2 = np.zeros((xlstm1.shape[0], hunits))\n",
    "\n",
    "print(\"inputlen2, samplenum\")\n",
    "print(inputlen ,samplenum, xlstm2.shape)\n",
    "\n",
    "\n",
    "for n in range(samplenum):\n",
    "    xlstm2[n] = intermediate_out(i,warr,uarr,barr, xlstm1[n], hunits, inputlen)\n",
    "    #print(a.shape)\n",
    "    #xlstm2[n][0] = a\n",
    "    \n",
    "print(xlstm2[0, 0:10])\n",
    "print(prey[0, 0:10])\n",
    "print(xlstm2[1, 0:10])\n",
    "print(prey[1, 0:10])\n",
    "\n",
    "\n",
    "weightDENSE = np.array(model.get_weights()[6:8])\n",
    "warr, barr = weightDENSE\n",
    "\n",
    "xdense = np.zeros((xlstm2.shape[0], 1))\n",
    "for n in range(xlstm2.shape[0]):\n",
    "    xdense[n]=DenseLayer(xlstm2[n].T, warr, barr);\n",
    "\n",
    "    \n",
    "    \n",
    "np.set_printoptions(precision=6)\n",
    "test=10\n",
    "for i in range(test):\n",
    "    print(xdense[i])\n",
    "    print(prey[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-2a4e8887fa3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#xs  = np.array([0.003,0.002,1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mh_tm1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_tm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_tm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h3={}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xs' is not defined"
     ]
    }
   ],
   "source": [
    "#xs  = np.array([0.003,0.002,1])\n",
    "for i in range(len(xs)):\n",
    "    x_t = xs[i].reshape(1,1)\n",
    "    h_tm1,c_tm1 = LSTMlayer(weights,x_t,h_tm1,c_tm1)\n",
    "print(\"h3={}\".format(h_tm1))\n",
    "print(\"c3={}\".format(c_tm1))\n",
    "batch_size = 1\n",
    "len_ts = len(xs)\n",
    "nfeature = X_test.shape[2]\n",
    "\n",
    "inp = layers.Input(batch_shape= (batch_size, len_ts, nfeature),\n",
    "                       name=\"input\")  \n",
    "rnn,s,c = layers.LSTM(hunits, \n",
    "                         return_sequences=True,\n",
    "                         stateful=False,\n",
    "                         return_state=True,\n",
    "                         name=\"RNN\")(inp)\n",
    "states = models.Model(inputs=[inp],outputs=[s,c, rnn])\n",
    "\n",
    "for layer in states.layers:\n",
    "    for layer1 in model1.layers:\n",
    "        if layer.name == layer1.name:\n",
    "            layer.set_weights(layer1.get_weights())\n",
    "            \n",
    "h_t_keras, c_t_keras, rnn = states.predict(xs.reshape(1,len_ts,1))\n",
    "print(\"h3={}\".format(h_t_keras))\n",
    "print(\"c3={}\".format(c_t_keras))\n",
    "def get_LSTM_UWb(weight):\n",
    "    '''\n",
    "    weight must be output of LSTM's layer.get_weights()\n",
    "    W: weights for input\n",
    "    U: weights for hidden states\n",
    "    b: bias\n",
    "    '''\n",
    "    warr,uarr, barr = weight\n",
    "    gates = [\"i\",\"f\",\"c\",\"o\"]\n",
    "    hunit = uarr.shape[0]\n",
    "    U, W, b = {},{},{}\n",
    "    for i1,i2 in enumerate(range(0,len(barr),hunit)):\n",
    "        \n",
    "        W[gates[i1]] = warr[:,i2:i2+hunit]\n",
    "        U[gates[i1]] = uarr[:,i2:i2+hunit]\n",
    "        b[gates[i1]] = barr[i2:i2+hunit].reshape(hunit,1)\n",
    "    return(W,U,b)\n",
    "\n",
    "def get_LSTMweights(model1):\n",
    "    for layer in model1.layers:\n",
    "        if \"LSTM\" in str(layer):\n",
    "            w = layer.get_weights()\n",
    "            W,U,b = get_LSTM_UWb(w)\n",
    "            break\n",
    "    return W,U,b\n",
    "def vectorize_with_labels(W,U,b):\n",
    "    bs,bs_label,ws,ws_label,us,us_label=[],[],[],[],[],[]\n",
    "    for k in [\"i\",\"f\",\"c\",\"o\"]:\n",
    "        temp = list(W[k].flatten())\n",
    "        ws_label.extend([\"W_\"+k]*len(temp))\n",
    "        ws.extend(temp)\n",
    "\n",
    "        temp = list(U[k].flatten())\n",
    "        us_label.extend([\"U_\"+k]*len(temp))\n",
    "        us.extend(temp)    \n",
    "\n",
    "        temp = list(b[k].flatten())\n",
    "        bs_label.extend([\"b_\"+k]*len(temp))\n",
    "        bs.extend(temp)  \n",
    "    weight = ws + us + bs\n",
    "    wlabel = ws_label + us_label + bs_label\n",
    "    return(weight,wlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
